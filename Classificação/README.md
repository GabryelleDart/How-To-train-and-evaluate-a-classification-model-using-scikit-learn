# üìò Classifica√ß√£o com Scikit-learn
Este **How to** apresenta uma introdu√ß√£o completa a modelos de classifica√ß√£o, explicando conceitos, aplica√ß√µes, pr√©-processamento, avalia√ß√£o de performance e implementa√ß√£o pr√°tica em Python com scikit-learn.
## üìå O que √© Classifica√ß√£o?
Classifica√ß√£o √© uma t√©cnica de aprendizado supervisionado utilizada quando a vari√°vel alvo (y) √© categ√≥rica (categorias ou classes).
> üëâ Exemplo na √°rea da sa√∫de: diagnosticar se um paciente tem diabetes ou n√£o tem diabetes a partir de vari√°veis como idade, peso e hist√≥rico m√©dico.
### ‚ö° Diferen√ßa entre Classifica√ß√£o e Regress√£o
- Classifica√ß√£o ‚Üí prev√™ categorias (ex.: "Iris-setosa", "Iris-versicolor", "Iris-virginica").
- Regress√£o ‚Üí prev√™ valores cont√≠nuos (ex.: "n√≠vel de glicose = 135 mg/dL").
### üå∏ Exemplos de problemas resolvidos com Classifica√ß√£o
- Diagn√≥stico de doen√ßas (diabetes, c√¢ncer).

- Classifica√ß√£o de imagens m√©dicas (tumor benigno ou maligno).

- Previs√£o de risco de readmiss√£o hospitalar (alto, m√©dio, baixo).

 - Identifica√ß√£o de esp√©cies de plantas ou animais.
## üîπ Principais Algoritmos de Classifica√ß√£o no Scikit-learn
### 1. Regress√£o Log√≠stica (LogisticRegression)

- üìñ Apesar do nome, √© classificador. Modela a probabilidade de pertencer a uma classe.

- ‚úÖ Bom para problemas lineares e interpret√°veis.

- üè• Exemplo: prever se um paciente tem diabetes baseado em exames laboratoriais.

### 2. K-Nearest Neighbors (KNeighborsClassifier)

- üìñ Classifica novos pontos com base nas classes dos k vizinhos mais pr√≥ximos.

- ‚úÖ Simples, eficiente para datasets pequenos.

- üè• Exemplo: classificar tipo de c√©lula comparando com c√©lulas conhecidas.

### 3. Support Vector Classifier (SVC)

- üìñ Encontra o hiperplano que separa melhor as classes.

- ‚úÖ Excelente para problemas lineares e n√£o lineares usando kernel.

- üè• Exemplo: identificar pacientes de alto risco com base em m√∫ltiplos fatores.

### 4. Decision Tree Classifier (DecisionTreeClassifier)

- üìñ Divide os dados usando regras de decis√£o em √°rvore.

- ‚úÖ F√°cil de interpretar e visualizar.

- üè• Exemplo: decidir se um paciente deve receber um tratamento espec√≠fico.

### 5. Random Forest Classifier (RandomForestClassifier)

- üìñ Conjunto de √°rvores de decis√£o que votam na classe final.

- ‚úÖ Mais robusto que uma √°rvore individual.

- üè• Exemplo: prever diagn√≥stico de doen√ßa baseado em m√∫ltiplos exames.

### 6. Gradient Boosting Classifier (GradientBoostingClassifier)

- üìñ Cria √°rvores sequenciais, cada uma corrigindo os erros da anterior.

- ‚úÖ Alta performance em dados tabulares.

- üè• Exemplo: classificar risco de complica√ß√µes hospitalares.

### 7. AdaBoost Classifier (AdaBoostClassifier)

- üìñ D√° mais peso a exemplos onde o modelo anterior errou.

- ‚úÖ Bom para lidar com ru√≠do moderado.

- üè• Exemplo: prever readmiss√£o hospitalar em casos inconsistentes.

### 8. Naive Bayes (GaussianNB)

- üìñ Baseado no teorema de Bayes, assume independ√™ncia entre atributos.

- ‚úÖ Simples, r√°pido e funciona bem com pequenas amostras.

- üè• Exemplo: classificar pacientes com base em sintomas.

| Modelo                     | Descri√ß√£o                | Vantagens                | Desvantagens                           | Exemplo em Sa√∫de          |
|-----------------------------|--------------------------|--------------------------|----------------------------------------|--------------------------|
| LogisticRegression         | Probabilidade de classe  | Interpret√°vel            | Linear, n√£o captura rela√ß√µes complexas | Diagn√≥stico de diabetes   |
| KNeighborsClassifier       | Vizinhos mais pr√≥ximos   | Simples, n√£o param√©trico | Lento com muitos dados                 | Classifica√ß√£o de c√©lulas  |
| SVC                        | Hiperplano separador     | N√£o linear, robusto      | Pode ser lento em grandes bases        | Risco de complica√ß√µes     |
| DecisionTreeClassifier     | Regras de decis√£o        | F√°cil de interpretar     | Overfitting                            | Decis√£o de tratamento     |
| RandomForestClassifier     | Floresta de √°rvores      | Robusto, generaliza bem  | Menos interpret√°vel                    | Diagn√≥stico complexo      |
| GradientBoostingClassifier | √Årvores sequenciais      | Alta performance         | Mais lento que Random Forest           | Risco hospitalar          |
| AdaBoostClassifier         | Repondera√ß√£o de exemplos | Lida bem com ru√≠do       | Sens√≠vel a outliers extremos           | Readmiss√£o hospitalar     |
| GaussianNB                 | Probabilidade com Bayes  | Simples e r√°pido         | Sup√µe independ√™ncia                    | Classifica√ß√£o de sintomas |


## üå∏ Dataset Iris (Scikit-learn)
O dataset Iris √© um cl√°ssico de classifica√ß√£o. Cont√©m 150 flores de 3 esp√©cies:

- **Iris-setosa**

- **Iris-versicolor**

- **Iris-virginica**

Cada flor possui 4 caracter√≠sticas:

- Sepal Length (cm)

- Sepal Width (cm)

- Petal Length (cm)

- Petal Width (cm)

> Objetivo: prever a esp√©cie da flor com base nas medidas das p√©talas e s√©palas.

### üíª Carregando o dataset
```
from sklearn.datasets import load_iris
iris = load_iris()

X = iris.data      # Features (4 colunas)
y = iris.target    # Classes (0=setosa, 1=versicolor, 2=virginica)

print("Formato de X:", X.shape)  # (150, 4)
print("Formato de y:", y.shape)  # (150,)
```
### üßπ Pr√©-processamento dos Dados
Antes de treinar, os dados precisam ser preparados:
> O scikit learn j√° traz os dados do dataset `iris` pr√©-processado, contudo  √© recomendado reconferir, al√©m de que, para outros datasets, esses passos ser√£o de suma import√¢ncia.

> Para mais informa√ß√µes sobre pr√©- processamento de dados volte a [Pr√© Processamento](https://github.com/GabryelleDart/How-To-train-and-evaluate-a-classification-model-using-scikit-learn/tree/main/Pr%C3%A9-Processamento) .

1. Inspe√ß√£o inicial

    - Identificar tipos de dados, valores faltantes, outliers.

    - Ferramentas: df.info(), df.describe().

2. Tratar valores faltantes

    - Remover linhas/colunas incompletas.

    - Preencher com m√©dia/mediana (SimpleImputer).

3. Transformar vari√°veis categ√≥ricas

    - Ex.: ‚Äúfuma = sim/n√£o‚Äù ‚Üí converter para 0 e 1.

    - Usar OneHotEncoder ou pd.get_dummies.

4. Escalonar vari√°veis

    - Padr√£o comum: StandardScaler ou MinMaxScaler.

5. Separar dados de treino e teste
### üìè Treinando um modelo de classifica√ß√£o
O KNN (K-Nearest Neighbors) √© um dos algoritmos mais simples de classifica√ß√£o. Ele funciona de maneira muito intuitiva:
> Imagine que voc√™ est√° em um jardim cheio de flores de diferentes esp√©cies. Uma nova flor aparece e voc√™ quer descobrir a qual esp√©cie ela pertence.
> O KNN olha para as K flores mais pr√≥ximas dela (os vizinhos mais pr√≥ximos) e vota qual esp√©cie √© mais comum entre esses vizinhos. A esp√©cie mais frequente ser√° a previs√£o do modelo.
```
    from sklearn.neighbors import KNeighborsClassifier
    
    
    knn = KNeighborsClassifier(n_neighbors=3)

```
> üñê **n_neighbors=3** significa que o modelo vai olhar para as **3 flores mais pr√≥ximas** e escolher a esp√©cie que aparecer mais vezes.

Treinar o modelo significa ensinar o KNN usando os dados de treino. Ele vai "memorizar" as posi√ß√µes das flores no espa√ßo das caracter√≠sticas para que possa comparar com novas flores depois.
```
    knn.fit(X_train, y_train)

```
> ‚úÖ Aqui, n√£o h√° magia de c√°lculos complexos: o KNN apenas memoriza os exemplos de treino e suas classes.

> üìå Diferente de regress√£o linear, ele n√£o tenta desenhar uma linha, ele se baseia na proximidade.

### üìè Previs√µes
Agora podemos dar flores do conjunto de teste e perguntar ao KNN: ‚ÄúQual esp√©cie voc√™ acha que essa flor √©?‚Äù
```
    y_pred = knn.predict(X_test)
    print("Previs√µes do KNN:", y_pred)

```
> üí° Cada n√∫mero na lista y_pred representa a classe prevista:

> 0 ‚Üí Iris-setosa, 1 ‚Üí Iris-versicolor, 2 ‚Üí Iris-virginica

### üìà Avalia√ß√£o da Performance
Para classifica√ß√£o, usamos m√©tricas diferentes da regress√£o:
- **Acur√°cia** ‚Üí % de previs√µes corretas
- **Matriz de Confus√£o** ‚Üí mostra acertos e erros por classe
- **Precision, Recall e F1-score** ‚Üí medidas detalhadas por classe
```
    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
    
    accuracy = accuracy_score(y_test, y_pred)
    print("Acur√°cia:", accuracy)
    
    cm = confusion_matrix(y_test, y_pred)
    print("Matriz de Confus√£o:\n", cm)
    
    report = classification_report(y_test, y_pred, target_names=iris.target_names)
    print("Relat√≥rio de Classifica√ß√£o:\n", report)

```
> üîπ Interpretando a matriz de confus√£o:
> - Cada linha representa a classe real.
> - Cada coluna representa a classe prevista.
> - O ideal √© que todos os n√∫meros estejam na diagonal principal (acertos).
      
> üîπ Exemplo de interpreta√ß√£o:
> - Se a matriz mostra que algumas versicolor foram classificadas como virginica, isso indica que o modelo confundiu essas duas esp√©cies.
> - A acur√°cia geral mostra quanto ele acerta em porcentagem.

### üìù Dicas Importantes para Classifica√ß√£o
- Sempre verifique o balanceamento das classes; classes desbalanceadas podem prejudicar o modelo.
- Use cross-validation para avaliar robustez do modelo.
- Experimente diferentes algoritmos e compare acur√°cia e F1-score.
- Para problemas reais, trate valores faltantes, outliers e escalonamento cuidadosamente.
- Para modelos complexos (Random Forest, Boosting), use feature importance para interpretar os fatores mais relevantes.
